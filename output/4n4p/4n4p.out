here
here
here
here
Time taken to read file: 0.88s

Start of epoch 0
At step 10, Update gradient for each batch taken: 0.13s
At step 20, Update gradient for each batch taken: 0.13s
At step 30, Update gradient for each batch taken: 0.13s
At step 40, Update gradient for each batch taken: 0.13s
At step 50, Update gradient for each batch taken: 0.13s
At step 60, Update gradient for each batch taken: 0.13s
At step 70, Update gradient for each batch taken: 0.13s
At step 80, Update gradient for each batch taken: 0.12s
At step 90, Update gradient for each batch taken: 0.13s
At step 100, Update gradient for each batch taken: 0.13s
At step 110, Update gradient for each batch taken: 0.13s
Time taken: 41.06s
Training acc over epoch: 0.7660, Training loss (for one epoch) at step: 0.6996

Start of epoch 1
At step 10, Update gradient for each batch taken: 0.13s
At step 20, Update gradient for each batch taken: 0.13s
At step 30, Update gradient for each batch taken: 0.13s
At step 40, Update gradient for each batch taken: 0.13s
At step 50, Update gradient for each batch taken: 0.13s
At step 60, Update gradient for each batch taken: 0.13s
At step 70, Update gradient for each batch taken: 0.12s
At step 80, Update gradient for each batch taken: 0.13s
At step 90, Update gradient for each batch taken: 0.13s
At step 100, Update gradient for each batch taken: 0.13s
At step 110, Update gradient for each batch taken: 0.14s
Time taken: 40.99s
Training acc over epoch: 0.9428, Training loss (for one epoch) at step: 0.1876

Start of epoch 2
At step 10, Update gradient for each batch taken: 0.13s
At step 20, Update gradient for each batch taken: 0.13s
At step 30, Update gradient for each batch taken: 0.13s
At step 40, Update gradient for each batch taken: 0.13s
At step 50, Update gradient for each batch taken: 0.13s
At step 60, Update gradient for each batch taken: 0.13s
At step 70, Update gradient for each batch taken: 0.12s
At step 80, Update gradient for each batch taken: 0.12s
At step 90, Update gradient for each batch taken: 0.12s
At step 100, Update gradient for each batch taken: 0.12s
At step 110, Update gradient for each batch taken: 0.14s
Time taken: 41.83s
Training acc over epoch: 0.9648, Training loss (for one epoch) at step: 0.1185

Start of epoch 3
At step 10, Update gradient for each batch taken: 0.12s
At step 20, Update gradient for each batch taken: 0.12s
At step 30, Update gradient for each batch taken: 0.12s
At step 40, Update gradient for each batch taken: 0.12s
At step 50, Update gradient for each batch taken: 0.12s
At step 60, Update gradient for each batch taken: 0.12s
At step 70, Update gradient for each batch taken: 0.12s
At step 80, Update gradient for each batch taken: 0.12s
At step 90, Update gradient for each batch taken: 0.12s
At step 100, Update gradient for each batch taken: 0.12s
At step 110, Update gradient for each batch taken: 0.12s
Time taken: 41.36s
Training acc over epoch: 0.9714, Training loss (for one epoch) at step: 0.0953

Start of epoch 4
At step 10, Update gradient for each batch taken: 0.13s
At step 20, Update gradient for each batch taken: 0.13s
At step 30, Update gradient for each batch taken: 0.13s
At step 40, Update gradient for each batch taken: 0.12s
At step 50, Update gradient for each batch taken: 0.12s
At step 60, Update gradient for each batch taken: 0.12s
At step 70, Update gradient for each batch taken: 0.13s
At step 80, Update gradient for each batch taken: 0.13s
At step 90, Update gradient for each batch taken: 0.13s
At step 100, Update gradient for each batch taken: 0.13s
At step 110, Update gradient for each batch taken: 0.13s
Time taken: 40.99s
Training acc over epoch: 0.9754, Training loss (for one epoch) at step: 0.0823
Test loss: 0.0591060072183609
Test accuracy: 0.9847000241279602
Total run time: 215.06s